{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGIhoTI28mCf"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "The below block imports all needed libraries. Feel free to add additional libraries that you need and rerun below block.\n",
        "\n",
        "Two last lines inform you of the Pytorch version and the availability of GPU.\n",
        "The last line should print `GPU availability: True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N6cClJOO8dL",
        "outputId": "b692674a-63f9-4a60-8613-5b1ca71b285f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pytorch version:  2.5.1+cu121\n",
            "GPU availability:  False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "print('Pytorch version: ', torch.__version__)\n",
        "print('GPU availability: ', torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-K-36199b9p"
      },
      "source": [
        "# Download Dataset\n",
        "If you are familiar with Linux bash scripts, you can put `!` at the beginning of a command to order Colab of interpreting it as bash scripts instead of python scripts.\n",
        "\n",
        "The below block downloads MNIST dataset and decompresses it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgCT6iUz_EFn",
        "outputId": "f829fa27-94d1-4c59-fbbc-325d5d60beb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-11-22 21:56:01--  https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz [following]\n",
            "--2024-11-22 21:56:01--  https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15683414 (15M) [application/octet-stream]\n",
            "Saving to: ‘mnist_png.tar.gz.2’\n",
            "\n",
            "\rmnist_png.tar.gz.2    0%[                    ]       0  --.-KB/s               \rmnist_png.tar.gz.2  100%[===================>]  14.96M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-22 21:56:01 (117 MB/s) - ‘mnist_png.tar.gz.2’ saved [15683414/15683414]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\n",
        "!tar xzf mnist_png.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwNWWw6c-EBX"
      },
      "source": [
        "# Define Dataset Class\n",
        "\n",
        "In order to use a dataset, we need to design a pytorch Dataset Class to process it.\n",
        "In the block below, you are required to complete:\n",
        "\n",
        "* TODO1.1: `def __init__(root, transform)` function to build the MNIST dataset from images included in the `root` directory. Please add code below `TODO1` to complete this function. The dataset should be captured by two lists, i.e., `self.images` that contains all images of MNIST, and `self.labels` that contains the corresponding label of each image in `self.images`.\n",
        "* TODO1.2: `def __getitem__(index)` to draw a sample at `index` and its corresponding label. This function should return a tuple (X, y), where X is the image (numpy ndarray of shape 1x28x28) and y is a scalar from 0 to 9 representing X's label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ClXGBsu3PNHx"
      },
      "outputs": [],
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        for label in range(10):\n",
        "            label_dir = os.path.join(self.root, str(label))\n",
        "            if not os.path.exists(label_dir):\n",
        "                continue\n",
        "            for filename in os.listdir(label_dir):\n",
        "                filepath = os.path.join(label_dir, filename)\n",
        "                image = Image.open(filepath).convert('L')\n",
        "                image_np = np.array(image, dtype=np.uint8).reshape(1, 28, 28)\n",
        "                self.images.append(image_np)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        image_2d = image.reshape(28, 28)\n",
        "        image_pil = Image.fromarray(image_2d, mode='L')\n",
        "        if self.transform:\n",
        "            image_transformed = self.transform(image_pil)\n",
        "        else:\n",
        "            image_transformed = torch.from_numpy(image).float()\n",
        "        return image_transformed, label\n",
        "\n",
        "    def show_random(self):\n",
        "        indices = np.random.randint(0, len(self), [16, ])\n",
        "        f, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                ax[i, j].imshow(self.images[indices[i * 4 + j]].reshape(28, 28), cmap='gray')\n",
        "                ax[i, j].tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
        "                ax[i, j].set_title(f'Label: {self.labels[indices[i * 4 + j]]}')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tSCAusZQXV4"
      },
      "source": [
        "# Define Model Class\n",
        "\n",
        "Below is the source code to define neural networks that we will use for training.\n",
        "A pytorch model necessarily have two functions, i.e., `__init__`, which defines all layers of the network, and `forward`, which receives the input data and processes through all layers defined in `__init__`.\n",
        "\n",
        "TODO2: Finish the functions below as instructed to complete this Convolutional network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daCrD96Bgpfr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PytorchConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PytorchConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc = nn.Linear(in_features=16 * 24 * 24, out_features=10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def name(self):\n",
        "        return \"PytorchConvNet Convolutional Neural Network\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdCME6xeRMBq"
      },
      "source": [
        "# Create MNISTDataset objects and dataloaders\n",
        "Below, we create the objects to process training and testing sets of MNIST data.\n",
        "As there are no held-out validation set, we manually split the training set into training and validation subsets with the ratio of 8:2.\n",
        "\n",
        "After creating dataset objects, we wrap them by a Pytorch Dataloader to allow several necessary features in training deep learning models, e.g., mini-batch feeding, shuffling.\n",
        "\n",
        "***Note***: if you successfully complete `__init__` function of `MNISTDataset`, its `show_random` function would successfully randomly show 16 images and corresponding labels in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "4KgEjy2VEIhx",
        "outputId": "cd57dac8-2fdb-45bb-9806-9eb095613d2b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size:  48000\n",
            "Validation set size:  12000\n",
            "Testing set size:  10000\n"
          ]
        }
      ],
      "source": [
        "################################################################\n",
        "# Hyper parameters\n",
        "################################################################\n",
        "BATCH_SIZE = 128\n",
        "# Update the transform to convert grayscale images to 3 channels\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(padding=2),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
        "])\n",
        "\n",
        "################################################################\n",
        "# Create training and testing dataset and show random examples\n",
        "################################################################\n",
        "trainval_set = MNISTDataset('mnist_png/training', transform=transform)\n",
        "trainval_set.show_random()\n",
        "\n",
        "test_set = MNISTDataset('mnist_png/testing', transform=transform)\n",
        "\n",
        "################################################################\n",
        "# As there is no validation set\n",
        "# We split training dataset into training and validation sets\n",
        "################################################################\n",
        "train_size = int(0.8 * len(trainval_set))\n",
        "val_size = len(trainval_set) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(\n",
        "    dataset=trainval_set,\n",
        "    lengths=[train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "################################################################\n",
        "# Print lengths of subsets\n",
        "################################################################\n",
        "print('Training set size: ', len(train_set))\n",
        "print('Validation set size: ', len(val_set))\n",
        "print('Testing set size: ', len(test_set))\n",
        "\n",
        "################################################################\n",
        "# Print lengths of subsets\n",
        "################################################################\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset=val_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swcZkufvS9xT"
      },
      "source": [
        "# Create Model and Training Process\n",
        "\n",
        "In the below block, we create an object (our model) from the MLPNet deep neural network defined above.\n",
        "\n",
        "Then, we create the `criterion` that will compute a loss value from predictions genereated by our model and groundtruth labels. We also create the `optimizer`, which updates our model's learnable parameters based on the loss value to improve its performance.\n",
        "\n",
        "Finally, we start training the model through `EPOCHS` number of epochs. At each epoch, after training the model through the training subset, we evaluate its loss and accuracy on validation subset. Usually, we would base on the loss or accuracy on validation subset to pick out the best performed model during our training process.\n",
        "\n",
        "Your tasks:\n",
        "\n",
        "\n",
        "*   TODO 3: Based on average accuracy on validation set, save the model weights into a file. Hint: use `torch.save(model.state_dict(), PATH)` to save model weights into a file specified by `PATH`.\n",
        "*   TODO 4: Load the best model weights saved in `PATH` from above task into our `model`. Then, compute loss and accuracy of the best model on testing subset. Hint: use `checkpoint = torch.load(PATH)` to load content of file specified in `PATH` into `checkpoint`, then, use `model.load_state_dict(checkpoint)` to load parameters saved in `checkpoint` into `model`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqbyzc2JgIzf",
        "outputId": "9ef5800a-86f4-4858-a11a-785e2277f606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==>>> epoch: 0, train loss: 0.353314\n",
            "==>>> epoch: 0, val loss: 0.125480, val accuracy: 0.961333\n",
            "Best model saved with accuracy: 0.961333\n",
            "==>>> epoch: 1, train loss: 0.089367\n",
            "==>>> epoch: 1, val loss: 0.078215, val accuracy: 0.976000\n",
            "Best model saved with accuracy: 0.976000\n",
            "==>>> epoch: 2, train loss: 0.066771\n",
            "==>>> epoch: 2, val loss: 0.067873, val accuracy: 0.979667\n",
            "Best model saved with accuracy: 0.979667\n",
            "==>>> epoch: 3, train loss: 0.052348\n",
            "==>>> epoch: 3, val loss: 0.058678, val accuracy: 0.981167\n",
            "Best model saved with accuracy: 0.981167\n",
            "==>>> epoch: 4, train loss: 0.044431\n",
            "==>>> epoch: 4, val loss: 0.055843, val accuracy: 0.984333\n",
            "Best model saved with accuracy: 0.984333\n",
            "==>>> epoch: 5, train loss: 0.038435\n",
            "==>>> epoch: 5, val loss: 0.053837, val accuracy: 0.984833\n",
            "Best model saved with accuracy: 0.984833\n",
            "==>>> epoch: 6, train loss: 0.032768\n",
            "==>>> epoch: 6, val loss: 0.052980, val accuracy: 0.984250\n",
            "==>>> epoch: 7, train loss: 0.027655\n",
            "==>>> epoch: 7, val loss: 0.055625, val accuracy: 0.984167\n",
            "==>>> epoch: 8, train loss: 0.023404\n",
            "==>>> epoch: 8, val loss: 0.049398, val accuracy: 0.986000\n",
            "Best model saved with accuracy: 0.986000\n",
            "==>>> epoch: 9, train loss: 0.020533\n",
            "==>>> epoch: 9, val loss: 0.049370, val accuracy: 0.985333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-42b59a51096c>:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(best_torch_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.037737, Test accuracy: 0.987900\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "################################################################\n",
        "# Hyperparameters\n",
        "################################################################\n",
        "LR = 0.01  # learning rate\n",
        "EPOCHS = 10  # number of epochs to train model\n",
        "\n",
        "################################################################\n",
        "# Create model\n",
        "################################################################\n",
        "model = PytorchConvNet().cuda()\n",
        "\n",
        "################################################################\n",
        "# Create optimizer and criterion\n",
        "################################################################\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "################################################################\n",
        "# Training process\n",
        "################################################################\n",
        "best_acc = 0.0\n",
        "best_torch_path = 'torch_checkpoint.pt'\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (x, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x, target = x.cuda(), target.cuda()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, target)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'==>>> epoch: {epoch}, train loss: {avg_loss:.6f}')\n",
        "    model.eval()\n",
        "    correct_cnt, total_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, target) in enumerate(val_loader):\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "            out = model(x)\n",
        "            val_loss = criterion(out, target)\n",
        "            _, pred_label = torch.max(out, 1)\n",
        "            correct_cnt += (pred_label == target).sum().item()\n",
        "            total_loss += val_loss.item()\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    avg_acc = correct_cnt / len(val_set)\n",
        "    print(f'==>>> epoch: {epoch}, val loss: {avg_loss:.6f}, val accuracy: {avg_acc:.6f}')\n",
        "\n",
        "    if avg_acc > best_acc:\n",
        "        best_acc = avg_acc\n",
        "        torch.save(model.state_dict(), best_torch_path)\n",
        "        print(f'Best model saved with accuracy: {best_acc:.6f}')\n",
        "\n",
        "################################################################\n",
        "# Testing process\n",
        "################################################################\n",
        "checkpoint = torch.load(best_torch_path)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "correct_cnt, total_loss = 0, 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (x, target) in enumerate(test_loader):\n",
        "        x, target = x.cuda(), target.cuda()\n",
        "        out = model(x)\n",
        "        test_loss = criterion(out, target)\n",
        "        _, pred_label = torch.max(out, 1)\n",
        "        correct_cnt += (pred_label == target).sum().item()\n",
        "        total_loss += test_loss.item()\n",
        "avg_loss = total_loss / len(test_loader)\n",
        "avg_acc = correct_cnt / len(test_set)\n",
        "print(f'Test loss: {avg_loss:.6f}, Test accuracy: {avg_acc:.6f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "9n1JSyVarjXp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Helper functions\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "def convolve2d(input, kernels, stride=1, padding=0):\n",
        "    batch_size, C_in, H_in, W_in = input.shape\n",
        "    C_out, C_in_k, K_h, K_w = kernels.shape\n",
        "    assert C_in == C_in_k, \"Input channels don't match\"\n",
        "\n",
        "    # Padding\n",
        "    if padding > 0:\n",
        "        input_padded = np.pad(input,\n",
        "                              ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
        "                              mode='constant')\n",
        "    else:\n",
        "        input_padded = input\n",
        "\n",
        "    H_in_p, W_in_p = input_padded.shape[2], input_padded.shape[3]\n",
        "    H_out = (H_in_p - K_h) // stride + 1\n",
        "    W_out = (W_in_p - K_w) // stride + 1\n",
        "    output = np.zeros((batch_size, C_out, H_out, W_out))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for c_out in range(C_out):\n",
        "            for h in range(H_out):\n",
        "                for w in range(W_out):\n",
        "                    h_start = h * stride\n",
        "                    h_end = h_start + K_h\n",
        "                    w_start = w * stride\n",
        "                    w_end = w_start + K_w\n",
        "                    input_slice = input_padded[b, :, h_start:h_end, w_start:w_end]\n",
        "                    kernel = kernels[c_out]\n",
        "                    output[b, c_out, h, w] = np.sum(input_slice * kernel)\n",
        "    return output\n",
        "\n",
        "class NumpyConvNet:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.conv1_weights = np.random.randn(6, 3, 5, 5) * np.sqrt(2. / (3 * 5 * 5))\n",
        "        self.conv2_weights = np.random.randn(16, 6, 5, 5) * np.sqrt(2. / (6 * 5 * 5))\n",
        "        self.fc_weights = np.random.randn(16 * 24 * 24, 10) * np.sqrt(2. / (16 * 24 * 24))\n",
        "        self.cache = {}\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.cache['x'] = x\n",
        "        x_conv1 = convolve2d(x, self.conv1_weights, stride=1, padding=0)\n",
        "        self.cache['x_conv1'] = x_conv1\n",
        "        x_relu1 = relu(x_conv1)\n",
        "        self.cache['x_relu1'] = x_relu1\n",
        "        x_conv2 = convolve2d(x_relu1, self.conv2_weights, stride=1, padding=0)\n",
        "        self.cache['x_conv2'] = x_conv2\n",
        "        x_relu2 = relu(x_conv2)\n",
        "        self.cache['x_relu2'] = x_relu2\n",
        "        batch_size = x.shape[0]\n",
        "        x_flat = x_relu2.reshape(batch_size, -1)\n",
        "        self.cache['x_flat'] = x_flat\n",
        "        output = np.dot(x_flat, self.fc_weights)\n",
        "        self.cache['output'] = output\n",
        "        return output\n",
        "\n",
        "    def backward(self, output, target):\n",
        "        batch_size = output.shape[0]\n",
        "        num_classes = self.fc_weights.shape[1]\n",
        "        softmax_output = softmax(output)\n",
        "        target = target.astype(int)\n",
        "        target_one_hot = np.zeros_like(softmax_output)\n",
        "        target_one_hot[np.arange(batch_size), target] = 1\n",
        "        d_output = (softmax_output - target_one_hot) / batch_size\n",
        "\n",
        "        # FC\n",
        "        x_flat = self.cache['x_flat']\n",
        "        dW_fc = np.dot(x_flat.T, d_output)\n",
        "        dx_flat = np.dot(d_output, self.fc_weights.T)\n",
        "        dx_relu2 = dx_flat.reshape(self.cache['x_relu2'].shape)\n",
        "        dx_conv2 = dx_relu2 * relu_derivative(self.cache['x_conv2'])\n",
        "\n",
        "        # Conv 2\n",
        "        dW_conv2, dx_relu1 = self.conv_backward(dx_conv2, self.cache['x_relu1'], self.conv2_weights)\n",
        "        dx_conv1 = dx_relu1 * relu_derivative(self.cache['x_conv1'])\n",
        "\n",
        "        # Conv 1\n",
        "        dW_conv1, _ = self.conv_backward(dx_conv1, self.cache['x'], self.conv1_weights)\n",
        "\n",
        "        # Weights\n",
        "        self.fc_weights -= self.lr * dW_fc\n",
        "        self.conv2_weights -= self.lr * dW_conv2\n",
        "        self.conv1_weights -= self.lr * dW_conv1\n",
        "\n",
        "\n",
        "    def conv_backward(self, d_out, x, weights, stride=1, padding=0):\n",
        "        batch_size, C_in, H_in, W_in = x.shape\n",
        "        C_out, C_in_k, K_h, K_w = weights.shape\n",
        "        assert C_in == C_in_k, \"Input channels do not match.\"\n",
        "\n",
        "        if padding > 0:\n",
        "            x_padded = np.pad(x,\n",
        "                              ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
        "                              mode='constant')\n",
        "        else:\n",
        "            x_padded = x\n",
        "\n",
        "        dW = np.zeros_like(weights)\n",
        "        dx_padded = np.zeros_like(x_padded)\n",
        "\n",
        "        H_out, W_out = d_out.shape[2], d_out.shape[3]\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            for c_out in range(C_out):\n",
        "                for h in range(H_out):\n",
        "                    for w in range(W_out):\n",
        "                        h_start = h * stride\n",
        "                        h_end = h_start + K_h\n",
        "                        w_start = w * stride\n",
        "                        w_end = w_start + K_w\n",
        "                        x_slice = x_padded[b, :, h_start:h_end, w_start:w_end]\n",
        "                        dW[c_out] += d_out[b, c_out, h, w] * x_slice\n",
        "                        dx_padded[b, :, h_start:h_end, w_start:w_end] += d_out[b, c_out, h, w] * weights[c_out]\n",
        "\n",
        "        if padding > 0:\n",
        "            dx = dx_padded[:, :, padding:-padding, padding:-padding]\n",
        "        else:\n",
        "            dx = dx_padded\n",
        "\n",
        "        return dW, dx\n",
        "\n",
        "    def name(self):\n",
        "        return \"Sankalp's Numpy Simple Convolutional Neural Network\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3N6CQhrrwjO"
      },
      "outputs": [],
      "source": [
        "# TODO5: Finish training pipeline for Numpy implementation of ConvNet:\n",
        "\n",
        "# Set hyperparameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "# Initialize the Numpy-based model\n",
        "model = NumpyConvNet(lr=LEARNING_RATE)\n",
        "\n",
        "# Loss function (Cross-Entropy Loss)\n",
        "def cross_entropy_loss(output, target):\n",
        "    return -np.sum(target * np.log(output + 1e-9)) / target.shape[0]\n",
        "\n",
        "# One-hot encoding for labels\n",
        "def one_hot_encode(labels, num_classes=10):\n",
        "    return np.eye(num_classes)[labels]\n",
        "\n",
        "# TODO5.1: Store best checkpoint for testing later.\n",
        "best_ckpt = None\n",
        "best_acc = 0.0\n",
        "\n",
        "# Training process\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch_idx, (x, target) in enumerate(train_loader):\n",
        "        # Convert PyTorch tensors to NumPy arrays\n",
        "        batch_x = x.numpy()  # Shape: (BATCH_SIZE, 3, 32, 32)\n",
        "        batch_y = target.numpy().astype(int)\n",
        "        batch_y_one_hot = one_hot_encode(batch_y, num_classes=10)\n",
        "\n",
        "        outputs = model.forward(batch_x)\n",
        "        probabilities = softmax(outputs)\n",
        "        loss = cross_entropy_loss(probabilities, batch_y_one_hot)\n",
        "        total_loss += loss\n",
        "        model.backward(outputs, batch_y)\n",
        "\n",
        "        predictions = np.argmax(probabilities, axis=1)\n",
        "        correct = np.sum(predictions == batch_y)\n",
        "        total_correct += correct\n",
        "        total_samples += batch_x.shape[0]\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # TODO5.3: Evaluation after each epoch after this line\n",
        "    val_total_loss = 0\n",
        "    val_total_correct = 0\n",
        "    val_total_samples = 0\n",
        "\n",
        "    for val_x, val_target in test_loader:\n",
        "        val_batch_x = val_x.numpy()\n",
        "        val_batch_y = val_target.numpy()\n",
        "        val_outputs = model.forward(val_batch_x)\n",
        "        val_probabilities = softmax(val_outputs)\n",
        "        val_batch_y_one_hot = one_hot_encode(val_batch_y, num_classes=10)\n",
        "        val_loss = cross_entropy_loss(val_probabilities, val_batch_y_one_hot)\n",
        "        val_total_loss += val_loss\n",
        "\n",
        "        val_predictions = np.argmax(val_probabilities, axis=1)\n",
        "        val_correct = np.sum(val_predictions == val_batch_y)\n",
        "        val_total_correct += val_correct\n",
        "        val_total_samples += val_batch_x.shape[0]\n",
        "\n",
        "    val_avg_loss = val_total_loss / len(test_loader)\n",
        "    val_accuracy = (val_total_correct / val_total_samples) * 100\n",
        "\n",
        "    print(f'Validation Loss: {val_avg_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "    if val_accuracy > best_acc:\n",
        "        best_acc = val_accuracy\n",
        "        best_ckpt = {\n",
        "            'conv1_weights': model.conv1_weights.copy(),\n",
        "            'conv2_weights': model.conv2_weights.copy(),\n",
        "            'fc_weights': model.fc_weights.copy()\n",
        "        }\n",
        "\n",
        "# TODO5.4: Test the best checkpoint\n",
        "model.conv1_weights = best_ckpt['conv1_weights']\n",
        "model.conv2_weights = best_ckpt['conv2_weights']\n",
        "model.fc_weights = best_ckpt['fc_weights']\n",
        "\n",
        "test_total_loss = 0\n",
        "test_total_correct = 0\n",
        "test_total_samples = 0\n",
        "\n",
        "for test_x, test_target in test_loader:\n",
        "    test_batch_x = test_x.numpy()\n",
        "    test_batch_y = test_target.numpy()\n",
        "    test_outputs = model.forward(test_batch_x)\n",
        "    test_probabilities = softmax(test_outputs)\n",
        "    test_batch_y_one_hot = one_hot_encode(test_batch_y, num_classes=10)\n",
        "    test_loss = cross_entropy_loss(test_probabilities, test_batch_y_one_hot)\n",
        "    test_total_loss += test_loss\n",
        "\n",
        "    test_predictions = np.argmax(test_probabilities, axis=1)\n",
        "    test_correct = np.sum(test_predictions == test_batch_y)\n",
        "    test_total_correct += test_correct\n",
        "    test_total_samples += test_batch_x.shape[0]\n",
        "\n",
        "test_avg_loss = test_total_loss / len(test_loader)\n",
        "test_accuracy = (test_total_correct / test_total_samples) * 100\n",
        "\n",
        "print(f'Test Loss: {test_avg_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
